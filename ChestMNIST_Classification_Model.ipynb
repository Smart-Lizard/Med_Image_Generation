{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smart-Lizard/Med_Image_Generation/blob/main/ChestMNIST_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "90mr3HIHwEvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce94294-10f4-4ace-ffbd-3c2ee09f7bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AehB1Nags7tz",
        "outputId": "2ca3edad-b34e-4c12-d6af-ef6efedcf1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.23.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (10.4.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.1+cu121)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=bfaecd4ce8a973b4d2d5b3d984dd34aa733dd48e56f647eda41d143d23853460\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.6.0 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "vhDIZQGCs9Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'chestmnist'\n",
        "download = True\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "info = INFO[data_flag]\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download, size=224, mmap_mode='r')\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsAUSfw-s_Y_",
        "outputId": "e4e1e674-5f9a-4338-c045-f9e3c03d0c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/chestmnist_224.npz?download=1 to /root/.medmnist/chestmnist_224.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3889293042/3889293042 [03:46<00:00, 17175237.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtF7Z2sPGX91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82594ca-16f3-4e93-f828-16c7f14f8b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/chestmnist_224.npz\n",
            "Using downloaded and verified file: /root/.medmnist/chestmnist_224.npz\n"
          ]
        }
      ],
      "source": [
        "# load the validation and test data\n",
        "val_dataset = DataClass(split='val', transform=data_transform, download=download, size=224, mmap_mode='r')\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download, size=224, mmap_mode='r')\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "label_mapping = ['atelectasis', 'cardiomegaly', 'effusion', 'infiltration', 'mass', 'nodule', 'pneumonia', 'pneumothorax', 'consolidation', 'edema', 'emphysema', 'fibrosis', 'pleural', 'hernia']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n",
        "!git clone https://github.com/rsm-13/classifying-chestMNIST.git\n",
        "%cd classifying-chestMNIST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ZKopmSz9Oo",
        "outputId": "f481e451-4e7e-40bb-a6f7-f3e7191ffde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Cloning into 'classifying-chestMNIST'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 17 (delta 2), reused 0 (delta 0), pack-reused 11 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17/17), 158.40 MiB | 12.28 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/classifying-chestMNIST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtRr32o6mVNk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/chestMNIST')\n",
        "from models import ResNet18\n",
        "net = ResNet18(in_channels=3, num_classes=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybfGzsBAmcN0"
      },
      "source": [
        "#### Hyperparameters and Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzXgzXAH-Cyo"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "lr = 0.001\n",
        "gamma=0.1\n",
        "milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "# Loss function (cross entropy for classification)\n",
        "loss_func = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wOU3CkcEd70"
      },
      "outputs": [],
      "source": [
        "def getAUC(y_true, y_score):\n",
        "    '''AUC metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    '''\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    auc = 0\n",
        "    for i in range(y_score.shape[1]):\n",
        "        label_auc = roc_auc_score(y_true[:, i], y_score[:, i])\n",
        "        auc += label_auc\n",
        "    ret = auc / y_score.shape[1]\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C3pKh5tGLpL"
      },
      "outputs": [],
      "source": [
        "def getACC(y_true, y_score, threshold=0.5):\n",
        "    '''Accuracy metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    :param threshold: the threshold for multilabel and binary-class tasks\n",
        "    '''\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    y_pre = y_score > threshold\n",
        "    acc = 0\n",
        "    for label in range(y_true.shape[1]):\n",
        "        label_acc = accuracy_score(y_true[:, label], y_pre[:, label])\n",
        "        acc += label_acc\n",
        "    ret = acc / y_true.shape[1]\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imRc0O8bGo7Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "def test(model, split_labels, data_loader, criterion, device='cuda', raw=False):\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = []\n",
        "    y_score = torch.tensor([]).to('cpu')\n",
        "\n",
        "    with torch.no_grad():  # No gradient computation in evaluation mode\n",
        "        for batch in data_loader:\n",
        "            inp, labels = batch\n",
        "\n",
        "            # Expand from 1 channel to 3 channels in validation/test as well\n",
        "            if inp.shape[1] == 1:  # If grayscale, repeat the channel to make it RGB\n",
        "                inp = inp.repeat(1, 3, 1, 1)\n",
        "\n",
        "            inp = inp.cuda(non_blocking=True).float()\n",
        "            out = model(inp)\n",
        "            labels = labels.to(torch.float32).cuda(non_blocking=True)\n",
        "            loss = criterion(out, labels)\n",
        "\n",
        "            # Get predictions from scores\n",
        "            sigmoid = torch.nn.Sigmoid()\n",
        "            answers = sigmoid(out).data.cpu()\n",
        "\n",
        "            # Recording values\n",
        "            y_score = torch.cat((y_score, answers), 0)\n",
        "            total_loss.append(loss.item())\n",
        "\n",
        "        y_score = y_score.cpu().data.numpy()\n",
        "        auc = getAUC(split_labels, y_score)\n",
        "        acc = getACC(split_labels, y_score)\n",
        "\n",
        "        testing_loss = np.mean(total_loss)\n",
        "\n",
        "        if raw:\n",
        "            return [testing_loss, auc, acc, split_labels, y_score]\n",
        "\n",
        "        return [testing_loss, auc, acc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE-ikzDYGI-L"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QS7PkG6e37-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e9088f-8502-44dc-c927-2634c830bc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 is the best yet with Val AUC = 0.6778519563574121\n",
            "Epoch 1 is the best yet with Val AUC = 0.7027811745649607\n"
          ]
        }
      ],
      "source": [
        "net.cuda()\n",
        "\n",
        "best_epoch = 0\n",
        "best_auc = 0\n",
        "best_model = net\n",
        "val_labels = val_dataset.labels\n",
        "\n",
        "for epoch in range(num_epochs): # We go over the data ten times\n",
        "    losses = []\n",
        "    net.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        inp, labels = batch\n",
        "\n",
        "        # Expand from 1 channel to 3 channels\n",
        "        if inp.shape[1] == 1:\n",
        "            inp = inp.repeat(1, 3, 1, 1)\n",
        "\n",
        "        inp = inp.cuda().to(torch.float32)\n",
        "        out = net(inp)\n",
        "        labels = labels.to(torch.float32).cuda()\n",
        "        loss = loss_func(out, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = np.mean(losses)\n",
        "    val_metrics = test(net, val_labels, val_loader, loss_func)\n",
        "\n",
        "    cur_auc = val_metrics[1]\n",
        "    if cur_auc > best_auc:\n",
        "        best_epoch = epoch\n",
        "        best_auc = cur_auc\n",
        "        best_model = net\n",
        "        print(f\"Epoch {best_epoch} is the best yet with Val AUC = {best_auc}\")\n",
        "        torch.save(best_model.state_dict(), '/content/drive/MyDrive/best_model.pth')\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqB9HU7hhmh9"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), '/content/drive/MyDrive/final_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sgMHXVYGiMi"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XNsRnjCUl97"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxwj9DSgNaSo"
      },
      "outputs": [],
      "source": [
        "test_metrics = test(net, chest['test_labels'], test_dataloader, loss_func, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGM0N9hgP379"
      },
      "outputs": [],
      "source": [
        "y_true, y_score = test_metrics[-2], test_metrics[-1]\n",
        "print(f\"Test AUC: {test_metrics[1]:5f} \\nTest ACC: {test_metrics[2]:5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA61sCbaSgrm"
      },
      "outputs": [],
      "source": [
        "y_pre = y_score > 0.5\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pre, average='samples', zero_division=1)\n",
        "print(f\"Test Precision: {precision:.5f}\\nTest Recall: {recall:.5f}\\nTest F1: {f1:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NYzaXi3mnSY"
      },
      "source": [
        "This high precision and low recall means that our model predicts many samples as positive – we will have a high number of true positives, but a high number of false positives, too.\n",
        "\n",
        "Intuitively, you can think of this as the model casting a wide net to catch a lot of the positive samples, which it does, but it also catches other things too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40btsOmPlyIn"
      },
      "source": [
        "We're calculating the above metrics sample-wise, i.e., we compute all three metrics for all samples separately, and returning the sample-weighted average.\n",
        "\n",
        "\n",
        "We're not calculating the metrics above class-wise, so it makes sense that it won't be similar to class-wise precision-recall-f1 scores computed belowh. I would recommend sticking to the overall accuracies listed above, as they are the most representative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvxXydzlhjVL"
      },
      "outputs": [],
      "source": [
        "for i in range(y_pre.shape[1]):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true[:, i], y_pre[:, i], average='micro', zero_division=1)\n",
        "    print(f\"Class {i}: Precision: {precision:.5f}\\tRecall: {recall:.5f}\\tF1: {f1:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWNaP-s-U6iL"
      },
      "outputs": [],
      "source": [
        "multilabel_confusion_matrix(y_true, y_pre, samplewise=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSCMA5GMWGLn"
      },
      "outputs": [],
      "source": [
        "for i in range(y_score.shape[1]):\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true[:, i], y_pre[:, i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}